---
title: AI Writing
date: '2025-11-23'
tags: ['misc']
draft: false
summary: It's weird.
---

> It's not about [X]: it's about [Y].

> At its core...

> This underscores...

> As we delve into the increasingly interconnected landscape of this dynamic, ever-shifting ecosystem, it becomes pivotal to underscore that itâ€™s not about simply optimizing discrete outcomes, but about reimagining a holistic, end-to-end paradigm that empowers stakeholders to unlock unprecedented synergies, catalyze transformative impact, and meaningfully align with the broader trajectory of sustainable, future-forward innovation.

Why does AI write like that? Like, I think AI writing is getting better,
but the really robotic, cliche way it writes is always just... jarring. It's like,
Linkedinese but taken to the extreme. Or that just means Linkedinese is derivative of ChatGPT writing,
which, honestly, is also a perfectly valid explanation.

I think GPT's main fault is that it writes in a super flowery and overly complex manner. In particular, it just loves to spit out sentences with 
an absurd amount of dependent clauses, as if it was Nathaniel Hawthorne writing the Scarlet Letter after preparing for the SAT and learning all of the grammar involved in that circus. Yeah, I know, *elite ball knowledge* or whatever the newest term is. 

AI also just has a tendency to use the same words and phrases over and over, to the point that reading it free-write is almost nauseating sometimes. It's like reading
a diplomat who just discovered LinkedIn: there's this excessively politically correct tone, while also the urge to write something that sounds impressive.
Because, although the sentence in the last example sounds impressive, what does it actually mean? It doesn't really have any personality. It's not trying to
say something. It's just putting words on a screen.

I'm no expert on AI, but maybe part of the reason GPT writes this way is because of the way it was trained. GPT wasn't trained on the everyday 
conversations between people: it was trained on internet documents, which tend to be more formal and neutral (unless you end up on InfoWars somehow). 
And I think that's just something that it doesn't really *get*: it doesn't inherently understand why we write, or the context in which we write it in. 

I will say that ChatGPT seems to do a reasonable job at wordsmithing, or just fixing a singular awkward sentence. The main issue is when GPT has the reins,
and is free to write whatever it wants.